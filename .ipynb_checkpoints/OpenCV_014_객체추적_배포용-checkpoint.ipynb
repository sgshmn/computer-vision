{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./lecture_image/00_title.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 객체 추적"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=1 width=100%>\n",
    "    <tr><td style=\"border: 1px solid black; width:600px; height:30px; text-align: center;\"><font size=4 color=blue><b>[14차시] 학습목표</b></font></td></tr>       \n",
    "    <tr><td style=\"border: 1px solid black; text-align: left;\"><font size=3>        \n",
    "○ 객체 추적방법에 대해 학습한다. <br><br>\n",
    "○ 배경 차분방법에 대해 학습한다. \n",
    "</font></td></tr>   \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ArpSZekuJnY"
   },
   "source": [
    "## MeanShift \n",
    "\n",
    "- 분포되어 있는 데이터에서 가장 밀집되어 있는 부분을 찾아내기 위한 기법\n",
    "- 알고리즘\n",
    "  - (1) 임의의 원을 데이터 공간에 그림 (Region of interest)\n",
    "  - (2) 원 안에 포함되어 있는 점들을 다 파악하여 x좌표, y좌표의 평균을 구함 (Center of mass)\n",
    "  - (3) 평균의 x, y좌표를 표시하고 그 좌표를 원의 중심으로 원을 움직임 (Mean Shift vector)\n",
    "  - (4) 이 작업을 반복 → 가우시안 분포의 중심으로 이동\n",
    "  \n",
    "- 영상에서 Mean Shift 방법은 평균 이동 알고리즘을 이용하여 관심 영역을 추적\n",
    "\n",
    "<img src=\"./lecture_image/14_meanshift.png\" width=50%>\n",
    "\n",
    "<img src=\"./lecture_image/14_meanshift2.gif\" width=40%>\n",
    "\n",
    "<center><font size=1>참고 : https://techlog.gurucat.net/146</font></center>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 초기 관심영역 선택\n",
    "\n",
    "- <font color=red>roi = cv2.selectROI(title, img, )</font>\n",
    "  - 마우스로 초기 관심영역 선택\n",
    "  - 선택한 영역의 좌상좌표 (x, y), 가로세로크기(w, h) 값을 반환\n",
    "  \n",
    "  \n",
    "- <font color=red>roi = cv2.selectROIs(title, img)</font>\n",
    "  - 마우스로 초기 관심영역 여러 개 선택\n",
    "  - 선택한 영역들의 좌상좌표 (x, y), 가로세로크기(w, h) 값을 반환  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 동영상에서 객체 추적\n",
    "\n",
    "- 동작 순서\n",
    "  - 영상에서 추적할 대상을 설정한 후 HSV 색상공간의 Hue(색상) 히스토그램을 계산\n",
    "  - 전체 영상에 대해 히스토그램을 계산 후 역투영 처리\n",
    "  - 역투영 처리된 영상에서 MeanShilft로 추적\n",
    "  \n",
    "  \n",
    "- 역투영 (BackProject) : 전체 영상의 색상 정보와 대상 객체의 색상 정보의 비율을 0~255 구간 내로 정규화\n",
    "\n",
    "   - <font color=red>backproj = cv2.calcBackProject([hsv이미지], [채널], 히스토그램, 채널의 범위, scale)</font>\n",
    "     - HSV 색상 영역에서 해당 채널 (H, S, V) 히스토그램에 대한 역투영\n",
    "     - 히스토그램으로 마스크를 구하고 실제 영상과 선택한 이미지를 AND 연산하여 원하는 색부분만 추출\n",
    "     - scale : 출력 역투영 행렬에 추가적으로 곱할 값\n",
    "\n",
    "\n",
    "- <font color=red>ret, win = cv2.meanShift(backproj, window, criteria)</font>\n",
    "  - backproj : 관심 객체에 대한 히스토그램 역투영 영상 (확률 영상)\n",
    "  - window: 초기 검색 영역 윈도우 & 결과 영역 반환\n",
    "  - criteria: 알고리즘 종료 기준 (type, maxCount, epsilon)\n",
    "   - cv2.TERM_CRITERIA_EPS : 주어진 정확도 (이동 크기)에 도달하면 반복 중단\n",
    "   - cv2.TERM_CRITERIA_COUNT : 반복 횟수에 도달하면 반복 중단\n",
    "   - (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1) ➔ 최대 10번 반복하며, 정확도가 1이하이면 (즉, 이동 크기가 1픽셀보다 작으면) 종료.\n",
    "    \n",
    "  - ret : 회전된 사각형 정보를 반환 - (x, y, width, height)\n",
    "  - win : 회전이 안된 사각형 정보를 반환    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CamShift \n",
    "- MeanShift의 문제점\n",
    "  - 탐색윈도우가 작을 때는 Local minimum 에 빠져서 더 이상 추적이 불가능\n",
    "  - 영상속의 물체가 커지거나 작아져도 ROI 크기가 일정\n",
    "  - 색상 히스토그램을 사용하는 경우 조도변화나 잡음에 민감<br>\n",
    " \n",
    "\n",
    "- CamShift 알고리즘 - MeanShift의 문제점을 보완\n",
    "  - (1) 관심영역 (ROI)가 주어지면 HSV 색 모델의 Hue값으로 변환\n",
    "  - (2) ROI의 1차원 히스토그램을 계산하고 추적 모델로 사용\n",
    "  - (3) 우선 평균 이동 알고리즘으로 이동 위치 계산\n",
    "  - (4) MeanShift가 수렴했다고 판단되면 이 위치에서 검색 윈도우의 윈도우 크기를 약간씩 키움 (기본적으로 10픽셀씩 키움)\n",
    "  - (5) 키운 윈도우 안에서 객체의 위치를 계산\n",
    "  - (6) 특징 공간을 가장 잘 표현하는 타원을 만들어서 타원의 크기만큼 윈도우 크기를 키움\n",
    "  - (7) 객체가 작아졌으면 타원의 크기가 작아짐\n",
    "  - (8) 검색 윈도우도 타원의 크기에 맞추어 작아짐\n",
    "  - (9) 새로운 크기의 윈도우를 이용하여 다시 평균 이동 수행\n",
    "  \n",
    "  <img src=\"./lecture_image/14_CAMshift.png\" width=70%>\n",
    "  \n",
    "<center><font size=1>참고 : https://www.researchgate.net/publication/264174083</font></center>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 동영상에서 객체 추적\n",
    "\n",
    "- <font color=red>ret, win = cv2.CamShift(probImage, window, criteria)</font>\n",
    "  - probImage: 관심 객체에 대한 히스토그램 역투영 영상 (확률 영상)\n",
    "  - window: 초기 검색 영역 윈도우 & 결과 영역 반환\n",
    "  - criteria: 알고리즘 종료 기준 (type, maxCount, epsilon)\n",
    "   - cv2.TERM_CRITERIA_EPS : 주어진 정확도 (이동 크기)에 도달하면 반복 중단\n",
    "   - cv2.TERM_CRITERIA_COUNT : 반복 횟수에 도달하면 반복 중단\n",
    "   - (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1) ➔ 최대 10번 반복하며, 정확도가 1이하이면 (즉, 이동 크기가 1픽셀보다 작으면) 종료.\n",
    "    \n",
    "  - ret : 회전된 사각형 정보를 반환 - (x, y, width, height)\n",
    "  - win : 회전이 안된 사각형 정보를 반환       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traker API\n",
    "- 참고 : https://pyimagesearch.com/2018/07/30/opencv-object-tracking/\n",
    "\n",
    "\n",
    "- <font color=red>tracker = cv2.TrackerXXX_create() </font>\n",
    "  - XXX Traker를 생성\n",
    "  - OpenCV에서 제공하는 Tracker의 종류\n",
    "    - Boosting : AdaBoost 알고리즘 기반\n",
    "    - MIL (Multiple Instance Learning) : 정확도 떨어짐\n",
    "    - KCF (Kernelized Correlation Filters) : MIL보다 속도는 빠르지만 가림 현상은 처리하지 못함\n",
    "    - CSRT (Channel and Spatial Reliability) : KCF보다 정확하지만 속도 느림 - 가장 우수\n",
    "    - MedianFlow : 객체의 전방향/역방향을 추적해서 불일치성을 측정, 빠르면 잘 동작하지 않음\n",
    "    - TLD (Tracking, Learning and Detection) : 가림 현상에 잘 동작하나 잘못 찾는 경우가 많음\n",
    "    - MOSSE : 내부적으로 그레이 스케일 사용, 정확도는 떨어지지만 속도가 빠름\n",
    "    - GOTURN : CNN 기반, 추가 모델(가중치 파일)이 필요함\n",
    "            \n",
    "            \n",
    "- <font color=red>isInit = tracker.init(frame, roi)</font>\n",
    "  - 이전 추적 위치로 추적 위치 초기화\n",
    "\n",
    "\n",
    "- <font color=red>ok, bbox = tracker.update(frame) </font>   \n",
    "  - 새로운 프레임에서 추적 위치 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(691, 239, 224, 210)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'rectangle'\n> Overload resolution failed:\n>  - rectangle() missing required argument 'color' (pos 4)\n>  - rectangle() missing required argument 'color' (pos 4)\n>  - Can't parse 'rec'. Expected sequence length 4, got 2\n>  - Can't parse 'rec'. Expected sequence length 4, got 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19348\\3908874577.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m             cv2.rectangle(img_draw,\n\u001b[0;32m     29\u001b[0m                           \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                           \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m                          )\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'rectangle'\n> Overload resolution failed:\n>  - rectangle() missing required argument 'color' (pos 4)\n>  - rectangle() missing required argument 'color' (pos 4)\n>  - Can't parse 'rec'. Expected sequence length 4, got 2\n>  - Can't parse 'rec'. Expected sequence length 4, got 2\n"
     ]
    }
   ],
   "source": [
    "tracker = None\n",
    "\n",
    "cap = cv2.VideoCapture('images/car.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    img_draw = frame.copy()\n",
    "    \n",
    "    # 트래커가 생성되지 않았다면 텍스트를 출력\n",
    "    # 트래커 : 추적하고자 하는 객체를 선택하는 것\n",
    "    \n",
    "    if tracker is None:\n",
    "        cv2.putText(img_draw, \"Press the spacebar to set ROI\",\n",
    "                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.75,\n",
    "                   (0, 0, 255), 2)\n",
    "        \n",
    "    else: # 추적할 객체를 선택한 경우\n",
    "        # 영상에서 선택한 ROI를 검색 (검색여부와 위치를 반환)\n",
    "        ok, bbox = tracker.update(frame)\n",
    "        (x, y, w, h) = bbox\n",
    "        \n",
    "        # 선택한 영역의 추적 결과를 영상에 표시\n",
    "        if ok:\n",
    "            cv2.rectangle(img_draw,\n",
    "                          (int(x), int(y)),\n",
    "                          (int(x + w), int(y + h))\n",
    "                         )\n",
    "        \n",
    "        \n",
    "    \n",
    "    key = cv2.waitKey(33)\n",
    "    cv2.imshow(\"object tracking\", img_draw)\n",
    "    \n",
    "    if key == 49:\n",
    "        break\n",
    "    elif key == ord(' '): # 스페이스바를 눌렀다면\n",
    "        # 추적 영역을 선택하면 (x, y, w, h를 반환)\n",
    "        roi = cv2.selectROI(\"Tracking\", frame)\n",
    "        \n",
    "        print(roi)\n",
    "        \n",
    "        # ROI를 선택했다면\n",
    "        if roi[2] and roi[3]: # w, h가 있으면\n",
    "            # 트래커 생성\n",
    "            tracker = cv2.TrackerMIL_create()\n",
    "            \n",
    "            # 트랙커를 선택한 영역으로 초기화\n",
    "            isinit = tracker.init(frame, roi)\n",
    "            \n",
    "        \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=1 width=100%>\n",
    "    <tr><td style=\"border: 1px solid black; width:600px; text-align: left;\"><font size=4 color=red><b>실습문제</b></font><br><br>\n",
    "        <font size=3>○ 다른 Tracker를 이용하여 객체 추적을 수행해보자.</font></td></tr> \n",
    "    \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 배경 차분 - MOG 배경 모델 \n",
    "\n",
    "## OpenCV의 배경 추정 알고리즘\n",
    "\n",
    "  \n",
    "  <img src=\"./lecture_image/14_mog1.png\" width=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOG : Mixture of Gaussian, GMM(Gaussian Mixture Model)\n",
    "- 각 픽셀에 대해 MOG 확률 모델을 설정하여 배경과 전경을 구분하는 방법\n",
    "  - (1) 영상의 각각의 픽셀 값을 배경 영상으로 정의\n",
    "  - (2) 미리 정의해둔 배경 영상의 각각의 픽셀마다 가우시안 모델을 정의\n",
    "  - (3) 픽셀 값이 정해진된 것이 아니라 픽셀 값이 가우시안 형태를 따르는 모델로 정의\n",
    "\n",
    "  <img src=\"./lecture_image/14_mog2.png\" width=70%>\n",
    "  \n",
    "- 배경 차분뿐만 아니라 데이터 사이언스에서 전반적으로 사용되는 데이터 분석 기법\n",
    "\n",
    "\n",
    "- <font color=red>bs = cv2.createBackgroundSubtractorMOG2()</font>\n",
    "  - 배경 차분 알고리즘 객체 생성\n",
    "  - <font color=red>bs = cv2.createBackgroundSubtractorKNN()</font> \n",
    "    - KNN을 이용 : 배경영상이 업데이트 되는 형태가 다름\n",
    "  - <font color=red>bs.setDetectShadows(False)</font>  \n",
    "    - 그림자 검출 안하면 0과 255로 구성된 마스크 출력\n",
    "\n",
    "- <font color=red>fgmask = bs.apply(gray)</font>\n",
    "  - 0또는 128또는 255로 구성된 fgmask 생성\n",
    "\n",
    "\n",
    "- <font color=red>backimg = bs.getBackgroundImage()</font>\n",
    "  - 추출된 배경 영상 반환\n",
    "\n",
    "\n",
    "- <font color=red>cnt, _, stats, _ = cv2.connectedComponentsWithStats(fgmask)</font>\n",
    "  - 객체 정보를 함께 반환하는 레이블링 함수    \n",
    "  - cnt : 객체 수 + 1 (배경 포함)\n",
    "  - labels : 객체에 번호가 지정된 레이블 맵\n",
    "  - stats : N행 5열, N은 객체 수 + 1이며 각각의 행은 번호가 지정된 객체를 의미, \n",
    "    - 5열 : x, y, width, height, area  \n",
    "    - x,y : 좌측 상단 좌표. area : 면적, 픽셀의 수\n",
    "  - centroids : N행 2열, 2열 (x, y : 무게 중심 좌표)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=1 width=100%>\n",
    "    <tr><td style=\"border: 1px solid black; width:600px; text-align: left;\"><font size=4 color=red><b>실습문제</b></font><br><br>\n",
    "        <font size=3>○ 다른 모델을 사용해서 전경과 배경을 분리해보자</font></td></tr>     \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=1 width=100%>\n",
    "    <tr><td style=\"border: 1px solid black; width:600px; height:40px; text-align: center;\"><font size=4 color=blue><b>[14차시] 정리하기</b></font></td></tr>       \n",
    "    <tr><td style=\"border: 1px solid black; text-align: left;\"><font size=3>\n",
    "        \n",
    "○ MeanShift : 분포되어 있는 데이터에서 가장 밀집되어 있는 부분을 찾아내기 위한 기법\n",
    "\n",
    "○ <font color=red>roi = cv2.selectROI(title, img, )</font> : 마우스로 초기 관심영역 선택\n",
    "\n",
    "○ MeanShift의 문제점\n",
    "  - 탐색윈도우가 작을 때는 Local minimum 에 빠져서 더 이상 추적이 불가능\n",
    "  - 영상속의 물체가 커지거나 작아져도 ROI 크기가 일정\n",
    "  - 색상 히스토그램을 사용하는 경우 조도변화나 잡음에 민감\n",
    "\n",
    "\n",
    "○ CamShift 알고리즘 - MeanShift의 문제점을 보완\n",
    "\n",
    "○ 배경 차분 : 각 픽셀에 대해 MOG 확률 모델을 설정하여 배경과 전경을 구분하는 방법                   \n",
    "</font></td></tr>   \n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DL008_03_OpenCV.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
